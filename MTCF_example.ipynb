{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Illustrating Example of how to use MTCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Import stuff and set visibility of GPU. The MTCF code is setup to use only one GPU.\n",
    "\n",
    "<span style=\"color:red\">Note:</span> This code MUST be run from the directory that houses this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import MTCF.MTCF as MTCF\n",
    "import MTCF.util as util\n",
    "from MTCF.parseAnnotations import parseVOTAnnotation, parseOTBAnnotation\n",
    "\n",
    "from IPython import display\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "\n",
    "# This code allows the notebook to only see 1 GPU\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # GPU number\n",
    "\n",
    "# Root path of the MTCF code base directory. There should be a folder MTCF/ in this directory with code\n",
    "root_path = os.path.abspath('.') + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Choose which video to track, and how many frames to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sequence_name = 'ball1'\n",
    "dataset = 'vot' # MUST be in ['otb', 'vot']\n",
    "num_frames_to_run = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Set the parameters of the MTCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = {# Stuff\n",
    "          'verbosity' : 1,\n",
    "          'color_names_filepath' : root_path + 'MTCF/lookup_tables/w2c.txt',\n",
    "    \n",
    "          # MTCF params\n",
    "          'max_trackers' : 8,\n",
    "          'max_tracker_images' : 50,\n",
    "          'num_frames_between_training' : 5,\n",
    "          'tracker_num_initial_images' : 5,\n",
    "          'tracker_weight_decay' : 0.2,\n",
    "    \n",
    "          # Base tracker params\n",
    "          'label_sigma_factor' : 1/16.,\n",
    "          'image_learning_rate' : 0.013,\n",
    "          'reg_lambda' : 1e-2,\n",
    "          'search_window_factor' : 5.,\n",
    "          'search_shape' : 'square', # must be in ['proportional', 'square']\n",
    "    \n",
    "          # Features params\n",
    "          'im_rep' : 'VGG16', # must be in ['HOG', 'HOG+CN', 'VGG16']\n",
    "          'VGG_layer_name' : 'block3_conv3',\n",
    "          'use_PCA' : True,\n",
    "          'VGG_PCA_num_components' : 64,\n",
    "          'HOG_PCA_num_components' : 15,\n",
    "          'CN_PCA_num_components' : 5,\n",
    "          'HOG_cell_size' : 4,\n",
    "    \n",
    "          # Template size params\n",
    "          'max_template_sidelength' : 48,\n",
    "          'min_template_sidelength' : 24,\n",
    "\n",
    "          # scale params\n",
    "          'num_scales' : 5,\n",
    "          'scale_step' : 1.02,\n",
    "\n",
    "          # Learning params\n",
    "          'LBFGSB_max_initial_learning_iters' : 100,\n",
    "          'LBFGSB_max_learning_iters' : 5,\n",
    "          \n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Get the absolute file paths of images and ground truth\n",
    "\n",
    "There a couple videos from OTB100/VOT2016 included with the codebase. If you have videos (with ground truth annotation in the same format as VOT/OTB), you can replace these absolute file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if dataset == 'vot': \n",
    "    video_path = root_path + 'videos/vot2016/' + sequence_name + '/'\n",
    "elif dataset == 'otb':\n",
    "    video_path = root_path + 'videos/otb100/' + sequence_name + '/'\n",
    "\n",
    "# Video statistics\n",
    "if dataset == 'vot':\n",
    "    vid_stats = util.VOT_video_statistics(video_path)\n",
    "elif dataset == 'otb':\n",
    "    vid_stats = util.OTB_video_statistics(video_path)\n",
    "frame_height = vid_stats['fh']\n",
    "frame_width = vid_stats['fw']\n",
    "num_frames_total = vid_stats['n_frames']\n",
    "\n",
    "# Get the ground truth bounding boxes\n",
    "if dataset == 'vot':\n",
    "    bounding_boxes = parseVOTAnnotation(video_path)\n",
    "elif dataset == 'otb':\n",
    "    bounding_boxes = parseOTBAnnotation(video_path)\n",
    "bboxes = np.stack([(bounding_boxes[i]['bx'], bounding_boxes[i]['by'], bounding_boxes[i]['width'], bounding_boxes[i]['height']) for i in xrange(1, num_frames_total+1)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Instantiate the MTCF\n",
    "\n",
    "First, we get the starting and ending frame numbers. \n",
    "\n",
    "Next, we get the first RGB image and ground truth (GT) bounding box.\n",
    "\n",
    "Finally, we use that to instantiate the MTCF. We also plot the first image for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get starting and ending frame numbers\n",
    "if dataset == 'otb':\n",
    "    config = json.load(open(video_path + 'cfg.json'))\n",
    "    image_start_frame = int(config['startFrame'])\n",
    "else:\n",
    "    image_start_frame = 1\n",
    "if num_frames_to_run > num_frames_total:\n",
    "    num_frames_to_run = num_frames_total\n",
    "image_end_frame = num_frames_to_run + image_start_frame - 1\n",
    "\n",
    "# Get the first image and GT bounding box\n",
    "image_filename = util.get_image_filename(image_start_frame, dataset)\n",
    "if dataset == 'otb' and not video_path.endswith('img/'):\n",
    "    images_path = video_path + 'img/'\n",
    "else:\n",
    "    images_path = video_path\n",
    "first_image = util.load_image_with_resize(images_path + image_filename)\n",
    "first_bbox = bboxes[image_start_frame-1, :] # indexing starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate MTCF\n",
    "mtcf = MTCF.MTCF(first_image, first_bbox, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Plot the first image with this GT bounding box\n",
    "img_copy = first_image.copy()\n",
    "cv2.rectangle(img_copy, tuple((first_bbox[:2] - np.array([first_bbox[2]/2, first_bbox[3]/2])).astype(int)), \n",
    "                        tuple((first_bbox[:2] + np.array([first_bbox[2]/2, first_bbox[3]/2])).astype(int)), \n",
    "                        (255, 0, 0), # red rectangle (RGB)\n",
    "                        2) # thickness of rectangle is two pixels    \n",
    "plt.imshow(img_copy.astype(np.uint8))\n",
    "plt.title(\"First Frame w/ GT bbox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run the tracker\n",
    "\n",
    "We plot a visualization of the tracker against the ground truth. Each frame of the video will be overlayed with the <span style=\"color:green\">predicted</span> bounding box in green, and the <span style=\"color:red\">ground truth</span> bounding box in red.\n",
    "\n",
    "<span style=\"color:red\">Note:</span> The speed of the tracker is not reflected in this notebook. The bottleneck is due to the notebook display clearing and painting the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "# Keep track of predictions, IoU, and scale factors.\n",
    "predicted_bboxes = []\n",
    "IoUs = []\n",
    "scale_factors = [1.0]\n",
    "\n",
    "# For loop over all frames for tracking. Start tracking at second frame\n",
    "start_time = time()\n",
    "for frame_num in xrange(image_start_frame+1, image_end_frame+1): \n",
    "\n",
    "    # Get the image\n",
    "    image_filename = util.get_image_filename(frame_num, dataset)\n",
    "    image = util.load_image_with_resize(images_path + image_filename)\n",
    "\n",
    "    # Get the ground truth bounding box\n",
    "    gt_bbox = bboxes[frame_num-1, :] # -1 because python indices start at 0\n",
    "\n",
    "    # Get the predicted bounding box\n",
    "    predicted_bbox = mtcf.track(image)\n",
    "    predicted_bboxes.append(predicted_bbox)\n",
    "\n",
    "    # Compute IOU, scale factor\n",
    "    iou = util.IoU(predicted_bbox, gt_bbox)\n",
    "    IoUs.append(iou)\n",
    "    scale_factors.append(mtcf.current_scale_factor)\n",
    "    \n",
    "    # Plot the image with ground truth (red) and prediction (green)\n",
    "    img_copy = image.copy()\n",
    "    cv2.rectangle(img_copy, tuple((gt_bbox[:2] - np.array([gt_bbox[2]/2, gt_bbox[3]/2])).astype(int)), \n",
    "                            tuple((gt_bbox[:2] + np.array([gt_bbox[2]/2, gt_bbox[3]/2])).astype(int)), \n",
    "                            (255, 0, 0), # red rectangle (RGB)\n",
    "                            2) # thickness of rectangle is two pixels    \n",
    "    cv2.rectangle(img_copy, tuple((predicted_bbox[:2] - np.array([predicted_bbox[2]/2, predicted_bbox[3]/2])).astype(int)), \n",
    "                            tuple((predicted_bbox[:2] + np.array([predicted_bbox[2]/2, predicted_bbox[3]/2])).astype(int)), \n",
    "                            (0, 255, 0), # green rectangle (RGB)\n",
    "                            2) # thickness of rectangle is two pixels\n",
    "    \n",
    "    # Clear the previous image and paint the current one.\n",
    "    plt.gca().cla()\n",
    "    plt.imshow(img_copy.astype(np.uint8))\n",
    "    plt.title(\"Frame {0} out of {1}\".format(frame_num, image_end_frame))\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf()) \n",
    "    \n",
    "# Print some stuff\n",
    "print \"Average IoU: {0}\".format(np.mean(IoUs))\n",
    "print \"Time taken to track: {0} seconds\".format(round(time() - start_time, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Recall, <span style=\"color:green\">predicted</span> bounding boxes are in green, and <span style=\"color:red\">ground truth</span> bounding boxes in red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Results\n",
    "\n",
    "We plot IoU and scale over time of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 5))\n",
    "\n",
    "# Plot IoU over time\n",
    "ax0 = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(np.arange(image_start_frame+1, image_end_frame+1), IoUs)\n",
    "plt.title('IoU. Average IoU: {0}'.format(np.mean(IoUs)))\n",
    "plt.xlabel('t')\n",
    "\n",
    "# Plot scale factor over time\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "plt.plot(np.arange(image_start_frame, image_end_frame+1), scale_factors)\n",
    "plt.title('Scale Factors')\n",
    "plt.xlabel('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
